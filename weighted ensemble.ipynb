{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress FutureWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"./dataset/heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "categorical_cols = ['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop('HeartDisease', axis=1)\n",
    "y = df['HeartDisease']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained models\n",
    "ann_model = load_model('./models/ANN.h5')\n",
    "gru_model = load_model('./models/GRU.h5')\n",
    "lstm_model = load_model('./models/LSTM.h5')\n",
    "mlp_model = load_model('./models/MLP.h5')\n",
    "rnn_model = load_model('./models/SimpleRNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of models\n",
    "models = [ann_model, gru_model, lstm_model, mlp_model, rnn_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step\n",
      "29/29 [==============================] - 1s 3ms/step\n",
      "29/29 [==============================] - 1s 3ms/step\n",
      "29/29 [==============================] - 0s 1ms/step\n",
      "29/29 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities\n",
    "y_pred_probs_ann = ann_model.predict(X)\n",
    "y_pred_probs_gru = gru_model.predict(X[:, None, :])\n",
    "y_pred_probs_lstm = lstm_model.predict(X[:, None, :])\n",
    "y_pred_probs_mlp = mlp_model.predict(X)\n",
    "y_pred_probs_rnn = rnn_model.predict(X[:, None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert probabilities to class predictions\n",
    "y_pred_ann = np.round(y_pred_probs_ann).astype(int)\n",
    "y_pred_gru = np.round(y_pred_probs_gru).astype(int)\n",
    "y_pred_lstm = np.round(y_pred_probs_lstm).astype(int)\n",
    "y_pred_mlp = np.argmax(y_pred_probs_mlp, axis=-1)\n",
    "y_pred_rnn = np.round(y_pred_probs_rnn).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure predictions are in the same shape\n",
    "y_pred_ann = y_pred_ann.flatten()\n",
    "y_pred_gru = y_pred_gru.flatten()\n",
    "y_pred_lstm = y_pred_lstm.flatten()\n",
    "y_pred_mlp = y_pred_mlp.flatten()\n",
    "y_pred_rnn = y_pred_rnn.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best weights: {'ann': 0.4777893212349693, 'gru': 0.0079517789617278, 'lstm': 0.1848300137476593, 'mlp': 0.04912543384503784, 'rnn': 0.2803034522106058}\n",
      "Best accuracy: 0.9455337690631809\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(weights, y_pred_ann, y_pred_gru, y_pred_lstm, y_pred_mlp, y_pred_rnn, y_true):\n",
    "    # Calculate weighted predictions\n",
    "    weighted_pred_ann = y_pred_ann * weights['ann']\n",
    "    weighted_pred_gru = y_pred_gru * weights['gru']\n",
    "    weighted_pred_lstm = y_pred_lstm * weights['lstm']\n",
    "    weighted_pred_mlp = y_pred_mlp * weights['mlp']\n",
    "    weighted_pred_rnn = y_pred_rnn * weights['rnn']\n",
    "    \n",
    "    # Sum the weighted predictions\n",
    "    ensemble_prediction = (\n",
    "        weighted_pred_ann +\n",
    "        weighted_pred_gru +\n",
    "        weighted_pred_lstm +\n",
    "        weighted_pred_mlp +\n",
    "        weighted_pred_rnn\n",
    "    )\n",
    "\n",
    "    # Convert probabilities to binary predictions (0 or 1)\n",
    "    ensemble_prediction_binary = np.round(ensemble_prediction)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(ensemble_prediction_binary == y_true)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "# Generate random weights\n",
    "def generate_random_weights():\n",
    "    weights = {\n",
    "        'ann': np.random.rand(),\n",
    "        'gru': np.random.rand(),\n",
    "        'lstm': np.random.rand(),\n",
    "        'mlp': np.random.rand(),\n",
    "        'rnn': np.random.rand()\n",
    "    }\n",
    "    # Normalize weights to sum up to 1\n",
    "    total_weight = sum(weights.values())\n",
    "    for key in weights:\n",
    "        weights[key] /= total_weight\n",
    "    return weights\n",
    "\n",
    "\n",
    "# Number of iterations for random weight generation\n",
    "num_iterations = 1000\n",
    "\n",
    "best_accuracy = 0\n",
    "best_weights = None\n",
    "\n",
    "# Iterate to find best weights\n",
    "for _ in range(num_iterations):\n",
    "    # Generate random weights\n",
    "    weights = generate_random_weights()\n",
    "    # Calculate accuracy for current weights\n",
    "    accuracy = calculate_accuracy(weights, y_pred_ann, y_pred_gru, y_pred_lstm, y_pred_mlp, y_pred_rnn, y)\n",
    "    # Check if current accuracy is the best so far\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_weights = weights\n",
    "\n",
    "print(\"Best weights:\", best_weights)\n",
    "print(\"Best accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">weights = {\n",
    "    'ann': 0.3,\n",
    "    'gru': 0.1,\n",
    "    'lstm': 0.1,\n",
    "    'mlp': 0.2,\n",
    "    'rnn': 0.3\n",
    "}\n",
    ">Final Accuracy: 0.9433551198257081"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best weights: {'ann': 0.40443884470235036, 'gru': 0.006678696432566848, 'lstm': 0.1902283489898096, 'mlp': 0.286984900907338, 'rnn': 0.11166920896793521}\n",
    "Best accuracy: 0.9455337690631809"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">weights = {\n",
    "    'ann': 0.4,\n",
    "    'gru': 0.1,\n",
    "    'lstm': 0.1,\n",
    "    'mlp': 0.1,\n",
    "    'rnn': 0.3\n",
    "}\n",
    ">Final Accuracy: 0.9455337690631809"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
